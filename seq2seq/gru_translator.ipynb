{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german vocabulary 10003\n",
      "english vocabulary 10003\n"
     ]
    }
   ],
   "source": [
    "# implementation of a translation model similar to the paper\n",
    "# \"Learning Phrase Representations using RNN Encoderâ€“Decoder\n",
    "# for Statistical Machine Translation\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "vocab_decode_path = 'de_en_vocab_decode.pkl'\n",
    "vocab_encode_path = 'de_en_vocab_encode.pkl'\n",
    "tokenized_dataset_path = 'de_en_tokenized_dataset.pkl'\n",
    "\n",
    "assert os.path.exists(vocab_decode_path)\n",
    "assert os.path.exists(vocab_encode_path)\n",
    "assert os.path.exists(tokenized_dataset_path)\n",
    "\n",
    "with open(tokenized_dataset_path, 'rb') as f: tokenized_dataset = pickle.load(f)\n",
    "with open(vocab_decode_path, 'rb') as f: vocab_decode = pickle.load(f)\n",
    "with open(vocab_encode_path, 'rb') as f: vocab_encode = pickle.load(f)\n",
    "\n",
    "assert len(tokenized_dataset['de']) == len(tokenized_dataset['en'])\n",
    "num_sentences = len(tokenized_dataset['de'])\n",
    "\n",
    "print('german vocabulary',len(vocab_decode['de']))\n",
    "print('english vocabulary',len(vocab_decode['en']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = torch.random.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# hyper parameters\n",
    "\n",
    "input_vocab_len = len(vocab_decode['de'])\n",
    "target_vocab_len = len(vocab_decode['en'])\n",
    "embed_dim = 256\n",
    "hidden_dim = 200\n",
    "\n",
    "# model parameters\n",
    "\n",
    "Ei = torch.randn((input_vocab_len, embed_dim), generator=rng, device=device) * 0.01\n",
    "Et = torch.randn((target_vocab_len, embed_dim), generator=rng, device=device) * 0.01\n",
    "\n",
    "Wr = torch.randn((embed_dim, hidden_dim), generator=rng, device=device) * ((5/3)/(embed_dim**0.5))\n",
    "Ur = torch.randn((hidden_dim, hidden_dim), generator=rng, device=device) * 0.01\n",
    "br = torch.zeros(hidden_dim, device=device)\n",
    "\n",
    "Qr = torch.randn((embed_dim, hidden_dim), generator=rng, device=device) * ((5/3)/(embed_dim**0.5))\n",
    "Vr = torch.randn((hidden_dim, hidden_dim), generator=rng, device=device) * 0.01\n",
    "cr = torch.zeros(hidden_dim, device=device)\n",
    "\n",
    "Wz = torch.randn((embed_dim, hidden_dim), generator=rng, device=device) * ((5/3)/(embed_dim**0.5))\n",
    "Uz = torch.randn((hidden_dim, hidden_dim), generator=rng, device=device) * 0.01\n",
    "bz = torch.zeros(hidden_dim, device=device)\n",
    "\n",
    "Qz = torch.randn((embed_dim, hidden_dim), generator=rng, device=device) * ((5/3)/(embed_dim**0.5))\n",
    "Vz = torch.randn((hidden_dim, hidden_dim), generator=rng, device=device) * 0.01\n",
    "cz = torch.zeros(hidden_dim, device=device)\n",
    "\n",
    "Wa = torch.randn((embed_dim, hidden_dim), generator=rng, device=device) * ((5/3)/(embed_dim**0.5))\n",
    "Ua = torch.randn((hidden_dim, hidden_dim), generator=rng, device=device) * 0.01\n",
    "ba = torch.zeros(hidden_dim, device=device)\n",
    "\n",
    "Qa = torch.randn((embed_dim, hidden_dim), generator=rng, device=device) * ((5/3)/(embed_dim**0.5))\n",
    "Va = torch.randn((hidden_dim, hidden_dim), generator=rng, device=device) * 0.01\n",
    "ca = torch.zeros(hidden_dim, device=device)\n",
    "\n",
    "Vy = torch.randn((hidden_dim, target_vocab_len), generator=rng, device=device) * 0.01\n",
    "\n",
    "params = [\n",
    "        Ei, Et,\n",
    "        Wr, Ur, br, Vr,\n",
    "        Wz, Uz, bz, Vz,\n",
    "        Wa, Ua, ba, Va,\n",
    "        Vy\n",
    "        ]\n",
    "for param in params: param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoder_forward(x, hprev):\n",
    "    emb = Ei[x]\n",
    "    pre_r = emb @ Wr + hprev @ Ur + br\n",
    "    r = F.sigmoid(pre_r)\n",
    "    pre_z = emb @ Wz + hprev @ Uz + bz\n",
    "    pre_a = emb @ Wa + (r * hprev) @ Ua + ba\n",
    "    z = F.sigmoid(pre_z)\n",
    "    a = torch.tanh(pre_a)\n",
    "    h = (1 - z) * hprev + z * a\n",
    "    return h\n",
    "\n",
    "def decoder_forward(x, hprev):\n",
    "    emb = Et[x]\n",
    "    pre_r = emb @ Qr + hprev @ Vr + cr\n",
    "    r = F.sigmoid(pre_r)\n",
    "    pre_z = emb @ Qz + hprev @ Vz + cz\n",
    "    pre_a = emb @ Qa + (r * hprev) @ Va + ca\n",
    "    z = F.sigmoid(pre_z)\n",
    "    a = torch.tanh(pre_a)\n",
    "    h = (1 - z) * hprev + z * a\n",
    "    y = h @ Vy\n",
    "    return y, h\n",
    "\n",
    "def compute_loss(inputs, targets, hprev, teacher_force=True):\n",
    "    h = hprev.clone()\n",
    "    input_tmax = len(inputs)\n",
    "    targets = targets.to_list()\n",
    "    targets.insert(0,0) # <SOS>\n",
    "    targets.append(1) # <EOS>\n",
    "    target_tmax = len(targets)\n",
    "    loss = 0.0\n",
    "    for t in range(input_tmax):\n",
    "        h = encoder_forward(inputs[t], h)\n",
    "    if teacher_force:\n",
    "        for t in range(target_tmax-1):\n",
    "            y, h = decoder_forward(targets[t], h)\n",
    "            target_one_hot = F.one_hot(torch.tensor(targets[t+1]),target_vocab_len).float()\n",
    "            loss += F.cross_entropy(y, target_one_hot)\n",
    "    else:\n",
    "        y = targets[0]\n",
    "        for t in range(target_tmax-1):\n",
    "            y, h = decoder_forward(y, h)\n",
    "            target_one_hot = F.one_hot(torch.tensor(targets[t+1]),target_vocab_len).float()\n",
    "            loss += F.cross_entropy(y, target_one_hot)\n",
    "            _, topi = y.topk(1)\n",
    "            y = topi.squeeze().detach()\n",
    "    return loss, h\n",
    "\n",
    "def sample(inputs):\n",
    "    h = torch.zeros(hidden_dim)\n",
    "    input_tmax = len(inputs)\n",
    "    for t in range(input_tmax):\n",
    "        h = encoder_forward(inputs[t], h)\n",
    "    y = 0\n",
    "    trans = ''\n",
    "    while True:\n",
    "        y, h = decoder_forward(y, h)\n",
    "        y = int(F.log_softmax(y,dim=-1).topk(1)[1])\n",
    "        out = vocab_decode['en'][y]\n",
    "        if out == '<EOS>':\n",
    "            break\n",
    "        trans += out\n",
    "    return trans\n",
    "        \n",
    "\n",
    "def evaluate(inputs, targets, hprev):\n",
    "    with torch.no_grad(): loss,h = compute_loss(inputs, targets, hprev)\n",
    "    return loss, h\n",
    "\n",
    "def train(inputs, targets, hprev, lr):\n",
    "    loss, h = compute_loss(inputs, targets, hprev)\n",
    "    for param in params: param.grad = None\n",
    "    loss.backward()\n",
    "    for param in params: param.data += -lr * param.grad\n",
    "    return loss.detach(), h.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step 0/2000: 82.9000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(X) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(Y) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m: \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m (train_steps\u001b[39m>>\u001b[39m\u001b[39m1\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m0.001\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss, hprev \u001b[39m=\u001b[39m train(X[\u001b[39m0\u001b[39;49m], Y[\u001b[39m0\u001b[39;49m], hprev, lr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m# print every once in a while\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain step \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtrain_steps\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m loss, h \u001b[39m=\u001b[39m compute_loss(inputs, targets, hprev)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m params: param\u001b[39m.\u001b[39mgrad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m params: param\u001b[39m.\u001b[39mdata \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39mlr \u001b[39m*\u001b[39m param\u001b[39m.\u001b[39mgrad\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joao/Documents/projects/neuralnets/seq2seq/gru_translator.ipynb#W1sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach(), h\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "n1 = int(.8*num_sentences)\n",
    "n2 = int(.9*num_sentences)\n",
    "train_range = (0, n1)\n",
    "val_range = (n1, n2)\n",
    "test_range = (n2, num_sentences)\n",
    "\n",
    "epochs = 10\n",
    "train_steps = 2000\n",
    "evaluate_steps = 1000\n",
    "test_steps = 2000\n",
    "lossi = []\n",
    "batch_size = 1\n",
    "\n",
    "for ep in range(epochs):\n",
    "    for i in range(train_steps):\n",
    "        hprev = torch.rand(hidden_dim, generator=rng)\n",
    "        ix = np.random.randint(train_range[0], train_range[1], (batch_size,))\n",
    "        X, Y = tokenized_dataset[ix]\n",
    "        if len(X) < 1 or len(Y) < 1: continue\n",
    "        lr = 0.1 if i < (train_steps>>1) else 0.001\n",
    "        loss, hprev = train(X[0], Y[0], hprev, lr)\n",
    "        if i % 100 == 0: # print every once in a while\n",
    "            print(f'train step {i}/{train_steps}: {loss.item():.4f}')\n",
    "        lossi.append(torch.log10(loss))\n",
    "    evaluate_loss = 0\n",
    "    for i in range(evaluate_steps):\n",
    "        ix = np.random.randint(train_range[0], train_range[1], (batch_size,))\n",
    "        X, Y = tokenized_dataset[ix]\n",
    "        if len(X) < 1 or len(Y) < 1: continue\n",
    "        loss, hprev = evaluate(X[0], Y[0], hprev)\n",
    "        if i % 100 == 0:\n",
    "            print(f'evaluate step {i}/{evaluate_steps}: {loss.item():.4f}')\n",
    "            print(f\"sample translation of `{' '.join(vocab_decode['de'][w] for w in X[0])}`: {sample(X[0])}\")\n",
    "        evaluate_loss += loss\n",
    "    avg_evaluate_loss = evaluate_loss/evaluate_steps\n",
    "    print(f'average validation loss: {avg_evaluate_loss.item():.4f}')\n",
    "    if avg_evaluate_loss <= 3.0:\n",
    "        break\n",
    "\n",
    "test_loss = 0\n",
    "hprev = torch.rand(hidden_dim, generator=rng)\n",
    "for i in range(test_steps):\n",
    "    ix = np.random.randint(train_range[0], train_range[1], (batch_size,))\n",
    "    X, Y = tokenized_dataset[ix]\n",
    "    if len(X) < 1 or len(Y) < 1: continue\n",
    "    loss, hprev = evaluate(X[0], Y[0], hprev)\n",
    "    test_loss += loss\n",
    "\n",
    "print(f'average test loss: {test_loss.item()/test_steps:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
